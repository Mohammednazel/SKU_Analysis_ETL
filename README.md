# ğŸš€ SKU Analysis Backend â€” Production Deployment Guide

**Repository:** [Ai-firelab/SKU_Analysis_Backend (dev3 branch)](https://github.com/Ai-firelab/SKU_Analysis_Backend/tree/dev3)  
**Stack:** FastAPI Â· PostgreSQL Â· Docker Â· Python ETL  
**Maintainer:** AI FireLab Data Engineering Team  

---

## ğŸ§  Overview

This project provides a **production-grade backend** for Procurement SKU Frequency & Spend Analysis.  
It includes:

- âš™ï¸ **ETL Pipeline:** Robust ingestion with checkpointing, retries, and resumable state.  
- ğŸ§© **Analytics API:** FastAPI-based endpoints powered by Materialized Views.  
- ğŸ•µï¸ **Monitoring & Alerts:** Email notifications for ETL failures or anomalies.  
- ğŸ³ **Dockerized Infrastructure:** API + ETL + PostgreSQL deployed seamlessly.

---

## ğŸ“ Project Structure

SKU_Analysis_Backend/
â”‚
â”œâ”€â”€ docker-compose.yml # Main orchestration (API, ETL, DB)
â”œâ”€â”€ Dockerfile # Base image definition
â”œâ”€â”€ .env.example # Safe environment template
â”œâ”€â”€ .gitignore # Excludes secrets/logs
â”œâ”€â”€ requirements.txt # Dependencies
â”œâ”€â”€ scripts/ # Cron and scheduling scripts
â”‚ â”œâ”€â”€ run_etl_daily.ps1
â”‚ â””â”€â”€ run_etl_daily.sh
â”‚
â”œâ”€â”€ src/
â”‚ â”œâ”€â”€ api/ # FastAPI app (main, routes, middleware)
â”‚ â”œâ”€â”€ etl/ # ETL pipeline (resilient ingestion)
â”‚ â”œâ”€â”€ db/ # Schema, materialized views, refresh logic
â”‚ â”œâ”€â”€ monitoring/ # Alerts, watchdogs, test alerting
â”‚ â””â”€â”€ common/ # Shared utility modules
â”‚
â””â”€â”€ docker-init/
â””â”€â”€ init.sql # DB bootstrap (auto-created on startup)

yaml
Copy code

---

## âš™ï¸ Setup Instructions

### ğŸªŸ For Windows PowerShell

1. **Clone the repository**
   ```powershell
   git clone -b dev3 https://github.com/Ai-firelab/SKU_Analysis_Backend.git
   cd SKU_Analysis_Backend
Create your environment file

powershell
Copy code
Copy-Item .env.example .env
Edit .env to set credentials

env
Copy code
DATABASE_URL=postgresql://postgres:password@postgres:5432/procurementdb
DATA_SOURCE_URL=https://procurement-sku-analysis-mock.onrender.com/purchase-orders
ENABLE_EMAIL_ALERTS=true
ALERT_EMAILS=yourname@company.com
SMTP_USER=youremail@gmail.com
SMTP_PASSWORD=your_app_password
ğŸ³ Docker Deployment
Build and start containers

powershell
Copy code
docker compose up -d --build
Check running containers

powershell
Copy code
docker ps
Check logs

powershell
Copy code
docker compose logs -f api
docker compose logs -f etl
When successful:

scss
Copy code
procurement_api       ... Up (port 8000)
procurement_etl       ... Exited (success)
procurementdb          ... Up (port 5432)
â–¶ï¸ Manual ETL Ingestion
Historical (Full Load)
powershell
Copy code
docker compose run --rm etl python src/etl/etl_ingest_resilient.py
Daily Incremental
Edit .env:

ini
Copy code
MODE=daily
HISTORICAL_TRUNCATE=false
Then:

powershell
Copy code
docker compose restart etl
ğŸ•’ Automated ETL Scheduling (Phase 5C.3)
Windows PowerShell + Task Scheduler
Create file: scripts/run_etl_daily.ps1

powershell
Copy code
cd "C:\path\to\SKU_Analysis_Backend"
docker compose run --rm etl python src/etl/etl_ingest_resilient.py
Then in Task Scheduler:

Action â†’ Start a program

Program: powershell.exe

Arguments: -File "C:\path\to\SKU_Analysis_Backend\scripts\run_etl_daily.ps1"

Trigger: Daily at 2:00 AM

âœ… Your ETL will run automatically each night and send alerts if issues occur.

ğŸ”” Monitoring & Alerts (Phase 2.9)
Alerts are handled by src/monitoring/alerting.py and include:

âŒ ETL failure

â±ï¸ Runtime exceeds threshold

âš ï¸ Zero rows processed

ğŸ’¤ No success in last 24 hours

Test alerts manually:
powershell
Copy code
docker compose run --rm etl python src/monitoring/test_alerting.py
If setup correctly, youâ€™ll receive test emails at addresses in ALERT_EMAILS.

ğŸ§© FastAPI Analytics API
Once Docker is running:

API URL â†’ http://127.0.0.1:8000

Swagger Docs â†’ http://127.0.0.1:8000/docs

Redoc â†’ http://127.0.0.1:8000/redoc

Health Check â†’ http://127.0.0.1:8000/api/v1/health

Example request:

powershell
Copy code
Invoke-WebRequest http://127.0.0.1:8000/api/v1/sku/top?limit=10
ğŸ§  Database Access & Verification
Access PostgreSQL inside Docker:

powershell
Copy code
docker exec -it procurementdb psql -U postgres -d procurementdb
Basic checks:

sql
Copy code
\dt
SELECT COUNT(*) FROM purchase_orders;
SELECT COUNT(*) FROM mv_sku_spend;
ğŸ§¹ Maintenance Tasks
Run PostgreSQL maintenance weekly:

powershell
Copy code
docker exec -it procurementdb psql -U postgres -d procurementdb -f src/db/performance_maintenance.sql
This performs:

VACUUM + ANALYZE

REINDEX

Refresh Materialized Views

Summarize table stats

ğŸ” Security Best Practices
âŒ Never commit .env â€” only .env.example.

Use App Passwords for Gmail SMTP.

Rotate SMTP credentials periodically.

Use Docker volumes for persistent PostgreSQL storage.

Restrict database access in production.

ğŸ§° Common PowerShell Commands
Action	Command
Build all containers	docker compose build
Start all containers	docker compose up -d
Stop containers	docker compose down
Restart ETL only	docker compose restart etl
Show ETL logs	docker compose logs -f etl
Show API logs	docker compose logs -f api
Access PostgreSQL shell	docker exec -it procurementdb psql -U postgres -d procurementdb

âš ï¸ Troubleshooting Guide
Issue	Cause	Fix
relation "purchase_orders" does not exist	DB not initialized	Run docker-init/init.sql
ETL stuck on chunk	Database lock	Restart DB container
Email alert not working	Wrong SMTP credentials	Use Gmail App Password
API returns 500	DB connection error	Check API logs
ETL retrying constantly	Source API rate-limited	Increase RATE_LIMIT_DELAY in .env

ğŸ“„ License & Ownership
Â© AI FireLab Data Engineering Team
Lead Developer: Mohammed Nazel
Branch: dev3
Environment: Dockerized PostgreSQL + FastAPI + Python ETL

For internal use within AI FireLab â€” not for public redistribution.

âœ… Quick Reference Summary
Start stack:

powershell
Copy code
docker compose up -d --build
Run ETL manually:

powershell
Copy code
docker compose run --rm etl python src/etl/etl_ingest_resilient.py
Open API docs:

arduino
Copy code
http://127.0.0.1:8000/docs
Check DB:

powershell
Copy code
docker exec -it procurementdb psql -U postgres -d procurementdb
Automated run (daily 2 AM):

Add to Task Scheduler â†’ scripts/run_etl_daily.ps1